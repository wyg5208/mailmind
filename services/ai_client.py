#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIé‚®ä»¶ç®€æŠ¥ç³»ç»Ÿ - AIå®¢æˆ·ç«¯
æ”¯æŒå¤šç§AIæœåŠ¡æä¾›å•†
"""

import requests
import json
import logging
import time
import threading
from typing import List, Dict, Optional, Callable
import re
from datetime import datetime

from config import Config
from services.translation_service import translation_service

logger = logging.getLogger(__name__)

class AIClient:
    def __init__(self):
        self.provider = Config.AI_PROVIDER
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        # å°è¯•ä»æ•°æ®åº“è·å–é…ç½®ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡
        try:
            from models.database import Database
            db = Database()
            
            self.provider = db.get_system_config('ai_provider', Config.AI_PROVIDER)
            
            if self.provider == 'glm':
                self.api_key = db.get_system_config('glm_api_key', Config.GLM_API_KEY)
                self.base_url = Config.GLM_BASE_URL
                self.model = db.get_system_config('glm_model', Config.GLM_MODEL)
            elif self.provider == 'openai':
                self.api_key = db.get_system_config('openai_api_key', Config.OPENAI_API_KEY)
                self.base_url = Config.OPENAI_BASE_URL
                self.model = db.get_system_config('openai_model', Config.OPENAI_MODEL)
            else:
                logger.warning(f"ä¸æ”¯æŒçš„AIæœåŠ¡æä¾›å•†: {self.provider}")
                
        except Exception as e:
            logger.warning(f"ä»æ•°æ®åº“åŠ è½½AIé…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
            # é™çº§åˆ°ç¯å¢ƒå˜é‡é…ç½®
            if self.provider == 'glm':
                self.api_key = Config.GLM_API_KEY
                self.base_url = Config.GLM_BASE_URL
                self.model = Config.GLM_MODEL
            elif self.provider == 'openai':
                self.api_key = Config.OPENAI_API_KEY
                self.base_url = Config.OPENAI_BASE_URL
                self.model = Config.OPENAI_MODEL
    
    def _clean_email_content(self, content: str) -> str:
        """æ¸…ç†é‚®ä»¶å†…å®¹ï¼Œç§»é™¤æ— ç”¨ä¿¡æ¯"""
        if not content:
            return ""
        
        # ç§»é™¤HTMLæ ‡ç­¾
        content = re.sub(r'<[^>]+>', '', content)
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        content = re.sub(r'\s+', ' ', content)
        
        # ç§»é™¤é‚®ä»¶ç­¾åï¼ˆç®€å•è§„åˆ™ï¼‰
        signature_patterns = [
            r'--\s*\n.*',  # -- å¼€å§‹çš„ç­¾å
            r'Best regards.*',
            r'Sent from.*',
            r'å‘è‡ª.*',
            r'æ­¤é‚®ä»¶.*è‡ªåŠ¨å‘é€.*'
        ]
        
        for pattern in signature_patterns:
            content = re.sub(pattern, '', content, flags=re.DOTALL | re.IGNORECASE)
        
        return content.strip()
    
    def _create_summary_prompt(self, email_data: Dict) -> str:
        """åˆ›å»ºé‚®ä»¶æ‘˜è¦æç¤ºè¯"""
        subject = email_data.get('subject', '')
        sender = email_data.get('sender', '')
        body = self._clean_email_content(email_data.get('body', ''))
        category = email_data.get('category', 'general')
        
        # æ ¹æ®é‚®ä»¶åˆ†ç±»è°ƒæ•´æ‘˜è¦é‡ç‚¹
        category_instructions = {
            'work': 'é‡ç‚¹å…³æ³¨å·¥ä½œä»»åŠ¡ã€æˆªæ­¢æ—¶é—´ã€ä¼šè®®å®‰æ’ç­‰å…³é”®ä¿¡æ¯',
            'finance': 'é‡ç‚¹å…³æ³¨é‡‘é¢ã€ä»˜æ¬¾æ—¶é—´ã€è´¦æˆ·ä¿¡æ¯ç­‰è´¢åŠ¡è¦ç‚¹',
            'social': 'é‡ç‚¹å…³æ³¨æ´»åŠ¨å®‰æ’ã€æ—¶é—´åœ°ç‚¹ç­‰ç¤¾äº¤ä¿¡æ¯',
            'shopping': 'é‡ç‚¹å…³æ³¨è®¢å•çŠ¶æ€ã€å•†å“ä¿¡æ¯ã€ç‰©æµä¿¡æ¯ç­‰',
            'news': 'é‡ç‚¹å…³æ³¨æ–°é—»è¦ç‚¹ã€å…³é”®äº‹ä»¶ç­‰',
            'general': 'æå–é‚®ä»¶çš„æ ¸å¿ƒä¿¡æ¯å’Œå…³é”®è¦ç‚¹'
        }
        
        instruction = category_instructions.get(category, category_instructions['general'])
        
        prompt = f"""
è¯·ä¸ºä»¥ä¸‹é‚®ä»¶ç”Ÿæˆç®€æ´å‡†ç¡®çš„ä¸­æ–‡æ‘˜è¦ï¼š

é‚®ä»¶ä¸»é¢˜ï¼š{subject}
å‘ä»¶äººï¼š{sender}
é‚®ä»¶å†…å®¹ï¼š{body[:1500]}  

è¦æ±‚ï¼š
1. {instruction}
2. æ‘˜è¦æ§åˆ¶åœ¨{Config.SUMMARY_MAX_LENGTH}å­—ä»¥å†…
3. çªå‡ºå…³é”®ä¿¡æ¯ï¼Œå¦‚æ—¶é—´ã€åœ°ç‚¹ã€é‡‘é¢ã€æˆªæ­¢æ—¥æœŸç­‰
4. è¯­è¨€ç®€æ´æ˜äº†ï¼Œé¿å…å†—ä½™
5. å¦‚æœæ˜¯é‡è¦é‚®ä»¶ï¼Œåœ¨å¼€å¤´æ ‡æ³¨[é‡è¦]
6. å¦‚æœå†…å®¹ä¸å®Œæ•´æˆ–æ— æ„ä¹‰ï¼Œè¯·è¯´æ˜"é‚®ä»¶å†…å®¹ä¸å®Œæ•´"

æ‘˜è¦ï¼š
"""
        return prompt.strip()
    
    def _call_glm_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨GLM API"""
        if not self.api_key:
            logger.error("GLM API key æœªé…ç½®")
            return None
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": Config.SUMMARY_TEMPERATURE,
            "max_tokens": Config.SUMMARY_MAX_LENGTH + 50,
            "stream": False
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    summary = result['choices'][0]['message']['content'].strip()
                    return self._post_process_summary(summary)
                else:
                    logger.error("GLM API è¿”å›æ ¼å¼é”™è¯¯")
                    return None
            else:
                error_text = response.text
                logger.error(f"GLM API è°ƒç”¨å¤±è´¥: {response.status_code} - {error_text}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("GLM API è°ƒç”¨è¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"GLM API è°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def _call_openai_api(self, prompt: str) -> Optional[str]:
        """è°ƒç”¨OpenAI API"""
        if not self.api_key:
            logger.error("OpenAI API key æœªé…ç½®")
            return None
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": Config.SUMMARY_TEMPERATURE,
            "max_tokens": Config.SUMMARY_MAX_LENGTH + 50
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                summary = result['choices'][0]['message']['content'].strip()
                return self._post_process_summary(summary)
            else:
                error_text = response.text
                logger.error(f"OpenAI API è°ƒç”¨å¤±è´¥: {response.status_code} - {error_text}")
                return None
                
        except Exception as e:
            logger.error(f"OpenAI API è°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def _post_process_summary(self, summary: str) -> str:
        """åå¤„ç†æ‘˜è¦å†…å®¹"""
        if not summary:
            return "æ‘˜è¦ç”Ÿæˆå¤±è´¥"
        
        # ç§»é™¤å¯èƒ½çš„æç¤ºè¯æ®‹ç•™
        summary = re.sub(r'^æ‘˜è¦[:ï¼š]\s*', '', summary)
        summary = re.sub(r'^æ€»ç»“[:ï¼š]\s*', '', summary)
        
        # å¯¹äºç®€æŠ¥æ‘˜è¦ï¼Œä¸å†å¼ºåˆ¶æˆªæ–­ï¼Œä¿ç•™å®Œæ•´å†…å®¹
        # å› ä¸ºæ™ºèƒ½åŠ©ç†æ‘˜è¦éœ€è¦æ›´å¤šç©ºé—´æ¥å±•ç¤ºè¯¦ç»†ä¿¡æ¯
        # åªåœ¨è¶…è¿‡1500å­—ç¬¦æ—¶æ‰æˆªæ–­ï¼ˆé˜²æ­¢æç«¯æƒ…å†µï¼‰
        max_allowed = 1500
        if len(summary) > max_allowed:
            summary = summary[:max_allowed - 3] + "..."
        
        return summary.strip()
    
    def _generate_fallback_summary(self, email_data: Dict) -> str:
        """ç”Ÿæˆå¤‡ç”¨æ‘˜è¦ï¼ˆå½“AIè°ƒç”¨å¤±è´¥æ—¶ï¼‰"""
        subject = email_data.get('subject', '')
        sender = email_data.get('sender', '')
        body = email_data.get('body', '')
        
        # æå–å‘ä»¶äººåç§°
        sender_name = sender.split('<')[0].strip() if '<' in sender else sender.split('@')[0]
        
        # ç®€å•çš„å…³é”®ä¿¡æ¯æå–
        body_preview = body[:100] + "..." if len(body) > 100 else body
        
        if not body.strip():
            return f"æ¥è‡ª {sender_name} çš„é‚®ä»¶ï¼š{subject}"
        else:
            return f"æ¥è‡ª {sender_name} çš„é‚®ä»¶ï¼š{subject}ã€‚å†…å®¹æ‘˜è¦ï¼š{body_preview}"
    
    def summarize_email(self, email_data: Dict) -> str:
        """ç”Ÿæˆå•å°é‚®ä»¶æ‘˜è¦"""
        try:
            prompt = self._create_summary_prompt(email_data)
            
            # æ ¹æ®é…ç½®çš„AIæä¾›å•†è°ƒç”¨ç›¸åº”API
            if self.provider == 'glm':
                summary = self._call_glm_api(prompt)
            elif self.provider == 'openai':
                summary = self._call_openai_api(prompt)
            else:
                logger.warning(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {self.provider}")
                summary = None
            
            # å¦‚æœAIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ‘˜è¦
            if not summary:
                summary = self._generate_fallback_summary(email_data)
                logger.warning(f"AIæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ‘˜è¦: {email_data.get('subject', 'Unknown')}")
            
            # è‡ªåŠ¨ç¿»è¯‘è‹±æ–‡æ‘˜è¦ä¸ºä¸­æ–‡
            if summary and translation_service.is_translation_available():
                try:
                    translated_summary = translation_service.translate_to_chinese(summary)
                    if translated_summary != summary:
                        logger.info(f"æ‘˜è¦å·²è‡ªåŠ¨ç¿»è¯‘: {email_data.get('subject', 'Unknown')}")
                        summary = translated_summary
                except Exception as e:
                    logger.warning(f"æ‘˜è¦ç¿»è¯‘å¤±è´¥: {e}")
            
            return summary
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆé‚®ä»¶æ‘˜è¦æ—¶å‡ºé”™: {e}")
            return self._generate_fallback_summary(email_data)
    
    def batch_summarize(self, emails: List[Dict]) -> List[Dict]:
        """æ‰¹é‡ç”Ÿæˆé‚®ä»¶æ‘˜è¦"""
        if not emails:
            return []
        
        logger.info(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(emails)} å°é‚®ä»¶çš„æ‘˜è¦")
        
        processed_emails = []
        success_count = 0
        
        for i, email_data in enumerate(emails):
            try:
                logger.debug(f"å¤„ç†é‚®ä»¶ {i+1}/{len(emails)}: {email_data.get('subject', 'Unknown')}")
                
                # æ£€æŸ¥é‚®ä»¶å†…å®¹æ˜¯å¦æœ‰æ•ˆ
                if not email_data.get('body', '').strip() and not email_data.get('subject', '').strip():
                    email_data['ai_summary'] = "é‚®ä»¶å†…å®¹ä¸ºç©º"
                    email_data['processed'] = True
                else:
                    # ç”ŸæˆAIæ‘˜è¦
                    ai_summary = self.summarize_email(email_data)
                    email_data['ai_summary'] = ai_summary
                    email_data['processed'] = True
                    success_count += 1
                
                processed_emails.append(email_data)
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                if i < len(emails) - 1:  # ä¸æ˜¯æœ€åä¸€å°é‚®ä»¶
                    time.sleep(0.5)  # 500mså»¶è¿Ÿ
                    
            except Exception as e:
                logger.error(f"å¤„ç†é‚®ä»¶æ‘˜è¦æ—¶å‡ºé”™: {e}")
                email_data['ai_summary'] = self._generate_fallback_summary(email_data)
                email_data['processed'] = True
                processed_emails.append(email_data)
        
        logger.info(f"æ‰¹é‡æ‘˜è¦ç”Ÿæˆå®Œæˆ: {success_count}/{len(emails)} æˆåŠŸ")
        return processed_emails
    
    def summarize_email_with_async_translation(self, email_data: Dict, callback: Optional[Callable] = None) -> str:
        """ç”Ÿæˆé‚®ä»¶æ‘˜è¦å¹¶å¼‚æ­¥ç¿»è¯‘"""
        try:
            prompt = self._create_summary_prompt(email_data)
            
            # æ ¹æ®é…ç½®çš„AIæä¾›å•†è°ƒç”¨ç›¸åº”API
            if self.provider == 'glm':
                summary = self._call_glm_api(prompt)
            elif self.provider == 'openai':
                summary = self._call_openai_api(prompt)
            else:
                logger.warning(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {self.provider}")
                summary = None
            
            # å¦‚æœAIè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ‘˜è¦
            if not summary:
                summary = self._generate_fallback_summary(email_data)
                logger.warning(f"AIæ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ‘˜è¦: {email_data.get('subject', 'Unknown')}")
            
            # å¼‚æ­¥ç¿»è¯‘è‹±æ–‡æ‘˜è¦ä¸ºä¸­æ–‡
            if summary and translation_service.is_translation_available():
                def translation_callback(translated_summary: str):
                    if translated_summary != summary:
                        logger.info(f"æ‘˜è¦å·²å¼‚æ­¥ç¿»è¯‘: {email_data.get('subject', 'Unknown')}")
                        email_data['ai_summary'] = translated_summary
                        # å¦‚æœæä¾›äº†å›è°ƒå‡½æ•°ï¼Œè°ƒç”¨å®ƒ
                        if callback:
                            callback(email_data, translated_summary)
                    elif callback:
                        callback(email_data, summary)
                
                try:
                    translation_service.translate_to_chinese_async(summary, translation_callback)
                except Exception as e:
                    logger.warning(f"å¼‚æ­¥ç¿»è¯‘å¯åŠ¨å¤±è´¥: {e}")
                    if callback:
                        callback(email_data, summary)
            elif callback:
                callback(email_data, summary)
            
            return summary
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆé‚®ä»¶æ‘˜è¦æ—¶å‡ºé”™: {e}")
            fallback_summary = self._generate_fallback_summary(email_data)
            if callback:
                callback(email_data, fallback_summary)
            return fallback_summary
    
    def batch_summarize_with_async_translation(self, emails: List[Dict], 
                                             progress_callback: Optional[Callable] = None) -> List[Dict]:
        """æ‰¹é‡ç”Ÿæˆé‚®ä»¶æ‘˜è¦å¹¶å¼‚æ­¥ç¿»è¯‘"""
        if not emails:
            return []
        
        logger.info(f"å¼€å§‹æ‰¹é‡ç”Ÿæˆ {len(emails)} å°é‚®ä»¶çš„æ‘˜è¦ï¼ˆå¼‚æ­¥ç¿»è¯‘ï¼‰")
        
        processed_emails = []
        success_count = 0
        translation_pending = []
        
        def translation_update_callback(email_data: Dict, translated_summary: str):
            """ç¿»è¯‘å®Œæˆåçš„å›è°ƒå‡½æ•°"""
            email_data['ai_summary'] = translated_summary
            email_data['translation_completed'] = True
            
            # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰ç¿»è¯‘éƒ½å®Œæˆäº†
            if all(email.get('translation_completed', False) for email in translation_pending):
                logger.info("æ‰€æœ‰é‚®ä»¶æ‘˜è¦ç¿»è¯‘å®Œæˆ")
                if progress_callback:
                    progress_callback('translation_completed', processed_emails)
        
        for i, email_data in enumerate(emails):
            try:
                logger.debug(f"å¤„ç†é‚®ä»¶ {i+1}/{len(emails)}: {email_data.get('subject', 'Unknown')}")
                
                # æ£€æŸ¥é‚®ä»¶å†…å®¹æ˜¯å¦æœ‰æ•ˆ
                if not email_data.get('body', '').strip() and not email_data.get('subject', '').strip():
                    email_data['ai_summary'] = "é‚®ä»¶å†…å®¹ä¸ºç©º"
                    email_data['processed'] = True
                    email_data['translation_completed'] = True
                else:
                    # ç”ŸæˆAIæ‘˜è¦ï¼ˆå¼‚æ­¥ç¿»è¯‘ï¼‰
                    ai_summary = self.summarize_email_with_async_translation(
                        email_data, translation_update_callback
                    )
                    email_data['ai_summary'] = ai_summary
                    email_data['processed'] = True
                    email_data['translation_completed'] = False  # ç­‰å¾…ç¿»è¯‘å®Œæˆ
                    translation_pending.append(email_data)
                    success_count += 1
                
                processed_emails.append(email_data)
                
                # æŠ¥å‘Šè¿›åº¦
                if progress_callback:
                    progress_callback('processing', {
                        'current': i + 1,
                        'total': len(emails),
                        'success': success_count
                    })
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                if i < len(emails) - 1:  # ä¸æ˜¯æœ€åä¸€å°é‚®ä»¶
                    time.sleep(0.5)  # 500mså»¶è¿Ÿ
                    
            except Exception as e:
                logger.error(f"å¤„ç†é‚®ä»¶æ‘˜è¦æ—¶å‡ºé”™: {e}")
                email_data['ai_summary'] = self._generate_fallback_summary(email_data)
                email_data['processed'] = True
                email_data['translation_completed'] = True
                processed_emails.append(email_data)
        
        logger.info(f"æ‰¹é‡æ‘˜è¦ç”Ÿæˆå®Œæˆ: æˆåŠŸ {success_count}/{len(emails)}, ç­‰å¾…ç¿»è¯‘: {len(translation_pending)}")
        
        # å¦‚æœæ²¡æœ‰éœ€è¦ç¿»è¯‘çš„é‚®ä»¶ï¼Œç«‹å³å®Œæˆ
        if not translation_pending and progress_callback:
            progress_callback('translation_completed', processed_emails)
        
        return processed_emails
    
    def generate_digest_summary(self, emails: List[Dict], is_manual_fetch: bool = False) -> str:
        """ç”Ÿæˆæ™ºèƒ½ç®€æŠ¥æ€»ç»“ - æ‹ŸäººåŒ–è´´å¿ƒåŠ©ç†é£æ ¼
        
        Args:
            emails: é‚®ä»¶åˆ—è¡¨
            is_manual_fetch: æ˜¯å¦ä¸ºæ‰‹åŠ¨å®æ—¶æ”¶å–ï¼ˆTrue=æ‰‹åŠ¨æ”¶å–ï¼ŒFalse=å®šæ—¶æ”¶å–ï¼‰
        """
        if not emails:
            return "ä¸»äººï¼Œä»Šå¤©è¿˜æ²¡æœ‰æ”¶åˆ°æ–°é‚®ä»¶å“¦~ ğŸ˜Š"
        
        # è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
        total_count = len(emails)
        categories = {}
        important_emails = []
        urgent_emails = []
        meetings = []
        tasks = []
        deadlines = []
        financial_items = []
        
        # æ™ºèƒ½åˆ†ææ¯å°é‚®ä»¶
        for email in emails:
            subject = email.get('subject', '').lower()
            body = email.get('body', '').lower()
            combined_text = f"{subject} {body[:500]}"
            
            # åˆ†ç±»ç»Ÿè®¡
            category = email.get('category', 'general')
            categories[category] = categories.get(category, 0) + 1
            
            # é‡è¦é‚®ä»¶è¯†åˆ«
            importance = email.get('importance', 1)
            if importance >= 3:
                urgent_emails.append(email)
            elif importance >= 2:
                important_emails.append(email)
            
            # ä¼šè®®è¯†åˆ«
            meeting_keywords = ['ä¼šè®®', 'meeting', 'ä¾‹ä¼š', 'è®¨è®º', 'discussion', 'é¢è°ˆ', 'zoom', 'è…¾è®¯ä¼šè®®']
            if any(keyword in combined_text for keyword in meeting_keywords):
                meetings.append({
                    'subject': email.get('subject', ''),
                    'sender': email.get('sender', ''),
                    'time': email.get('date', '')
                })
            
            # ä»»åŠ¡è¯†åˆ«
            task_keywords = ['ä»»åŠ¡', 'task', 'todo', 'å¾…åŠ', 'éœ€è¦å®Œæˆ', 'è¯·å¤„ç†', 'è¯·å®Œæˆ']
            if any(keyword in combined_text for keyword in task_keywords):
                tasks.append({
                    'subject': email.get('subject', ''),
                    'sender': email.get('sender', '')
                })
            
            # æˆªæ­¢æ—¥æœŸè¯†åˆ«
            deadline_keywords = ['æˆªæ­¢', 'deadline', 'æœ€è¿Ÿ', 'æˆªè‡³', 'due date', 'åˆ°æœŸ']
            if any(keyword in combined_text for keyword in deadline_keywords):
                deadlines.append({
                    'subject': email.get('subject', ''),
                    'sender': email.get('sender', '')
                })
            
            # è´¢åŠ¡ç›¸å…³
            if category == 'finance':
                financial_items.append({
                    'subject': email.get('subject', ''),
                    'sender': email.get('sender', '')
                })
        
        # æ ¹æ®æ˜¯å¦æ‰‹åŠ¨æ”¶å–ï¼Œå†³å®šæ˜¯å¦åŒ…å«æ—¶é—´é—®å€™
        greeting_instruction = ""
        if is_manual_fetch:
            # æ‰‹åŠ¨æ”¶å–ï¼šä¸éœ€è¦æ—¶é—´é—®å€™ï¼Œç›´æ¥èšç„¦é‚®ä»¶å†…å®¹
            greeting_instruction = """
1. **ç›´æ¥å¼€åœº**ï¼ˆ1å¥è¯ï¼‰ï¼šç›´æ¥è¯´æ˜æœ¬æ¬¡æ”¶å–åˆ°çš„é‚®ä»¶æƒ…å†µï¼Œä¾‹å¦‚ï¼š
   - "æœ¬æ¬¡ä¸ºæ‚¨æ”¶å–äº†XXå°é‚®ä»¶ï¼Œå…¶ä¸­..."
   - "åˆšåˆšæ”¶åˆ°äº†XXå°æ–°é‚®ä»¶..."
   - "è¿™æ¬¡å…±æ”¶å–åˆ°XXå°é‚®ä»¶..."
   æ³¨æ„ï¼šä¸è¦ä½¿ç”¨"æ—©ä¸Šå¥½/ä¸‹åˆå¥½/æ™šä¸Šå¥½"ç­‰æ—¶é—´é—®å€™è¯­"""
        else:
            # å®šæ—¶æ”¶å–ï¼šä½¿ç”¨åŸºäºä¸œå…«åŒºçš„æ—¶é—´é—®å€™
            from utils.timezone_helper import now_china_naive
            china_time = now_china_naive()
            current_hour = china_time.hour
            current_time_str = china_time.strftime('%H:%M')
            
            # ç¡®å®šé—®å€™è¯­
            if 6 <= current_hour < 12:
                expected_greeting = "æ—©ä¸Šå¥½ï¼â˜€ï¸"
            elif 12 <= current_hour < 18:
                expected_greeting = "ä¸‹åˆå¥½ï¼ğŸŒ¤ï¸"
            else:
                expected_greeting = "æ™šä¸Šå¥½ï¼ğŸŒ™"
            
            greeting_instruction = f"""
1. **æ—¶é—´é—®å€™**ï¼ˆ1å¥è¯ï¼‰ï¼šå½“å‰ä¸­å›½æ—¶é—´æ˜¯ {current_time_str}ï¼ˆ{current_hour}ç‚¹ï¼‰ï¼Œè¯·ä½¿ç”¨"{expected_greeting}"ä½œä¸ºå¼€åœºé—®å€™ï¼Œç„¶åç®€è¦è¯´æ˜é‚®ä»¶æƒ…å†µ"""
        
        # æ„å»ºAIé£æ ¼çš„æ™ºèƒ½æ‘˜è¦æç¤ºè¯
        prompt = f"""
ä½ æ˜¯ä¸€ä½è´´å¿ƒã€ä¸“ä¸šçš„é‚®ä»¶åŠ©ç†ï¼Œè¯·ç”¨ç”ŸåŠ¨æ´»æ³¼ã€æ¸©æš–å‹å¥½çš„å£å»ï¼Œä¸ºç”¨æˆ·ç”Ÿæˆé‚®ä»¶çš„æ™ºèƒ½æ‘˜è¦ã€‚

**é‚®ä»¶æ•°æ®ç»Ÿè®¡**ï¼š
- æ”¶åˆ°é‚®ä»¶æ€»æ•°ï¼š{total_count} å°
- ç´§æ€¥é‡è¦é‚®ä»¶ï¼š{len(urgent_emails)} å°
- éœ€è¦å…³æ³¨é‚®ä»¶ï¼š{len(important_emails)} å°
- ä¼šè®®é‚€è¯·/é€šçŸ¥ï¼š{len(meetings)} ä¸ª
- å¾…åŠä»»åŠ¡ï¼š{len(tasks)} é¡¹
- æœ‰æˆªæ­¢æ—¥æœŸçš„äº‹é¡¹ï¼š{len(deadlines)} é¡¹
- è´¢åŠ¡ç›¸å…³ï¼š{len(financial_items)} é¡¹

**åˆ†ç±»ç»Ÿè®¡**ï¼š
{json.dumps(categories, ensure_ascii=False, indent=2)}

**ç´§æ€¥é‚®ä»¶æ¦‚è¦**ï¼ˆå‰3ä¸ªï¼‰ï¼š
{json.dumps([{'ä¸»é¢˜': e.get('subject', ''), 'å‘ä»¶äºº': e.get('sender', '')} for e in urgent_emails[:3]], ensure_ascii=False, indent=2)}

**ä¼šè®®é€šçŸ¥æ¦‚è¦**ï¼ˆå‰3ä¸ªï¼‰ï¼š
{json.dumps(meetings[:3], ensure_ascii=False, indent=2)}

**ä»»åŠ¡æé†’æ¦‚è¦**ï¼ˆå‰3ä¸ªï¼‰ï¼š
{json.dumps(tasks[:3], ensure_ascii=False, indent=2)}

**æˆªæ­¢æ—¥æœŸæé†’**ï¼ˆå‰3ä¸ªï¼‰ï¼š
{json.dumps(deadlines[:3], ensure_ascii=False, indent=2)}

è¯·ç”Ÿæˆä¸€æ®µ**ä¸è¶…è¿‡500å­—**çš„æ™ºèƒ½æ‘˜è¦ï¼Œè¦æ±‚ï¼š

{greeting_instruction}
2. **æ€»ä½“æ¦‚å†µ**ï¼ˆ2-3å¥è¯ï¼‰ï¼šç”¨ç”ŸåŠ¨çš„è¯­è¨€æè¿°é‚®ä»¶æ€»æ•°å’Œé‡è¦ç¨‹åº¦åˆ†å¸ƒ
3. **é‡ç‚¹æé†’**ï¼ˆ3-5å¥è¯ï¼‰ï¼š
   - ç´§æ€¥é‚®ä»¶ï¼šå¦‚æœæœ‰ï¼Œç”¨å¼•äººæ³¨ç›®çš„æ–¹å¼çªå‡ºæœ€é‡è¦çš„1-2å°ï¼Œè¯´æ˜å…³é”®ä¿¡æ¯
   - ä¼šè®®æ—¥ç¨‹ï¼šå¦‚æœæœ‰ï¼Œç”ŸåŠ¨åœ°æé†’æ—¶é—´å’Œä¸»é¢˜
   - ä»»åŠ¡å¾…åŠï¼šå¦‚æœæœ‰ï¼Œæ´»æ³¼åœ°æé†’éœ€è¦å®Œæˆçš„äº‹é¡¹
   - æˆªæ­¢æ—¥æœŸï¼šå¦‚æœæœ‰ï¼Œç‰¹åˆ«å¼ºè°ƒä¸´è¿‘çš„deadlineï¼Œå¢åŠ ç´§è¿«æ„Ÿ
4. **è´¢åŠ¡æé†’**ï¼ˆå¯é€‰1-2å¥è¯ï¼‰ï¼šå¦‚æœæœ‰è´¦å•ã€ä»˜æ¬¾ç­‰è´¢åŠ¡é‚®ä»¶ï¼Œç”¨é†’ç›®çš„æ–¹å¼ç‰¹åˆ«æé†’
5. **è´´å¿ƒå»ºè®®**ï¼ˆ1-2å¥è¯ï¼‰ï¼šåŸºäºé‚®ä»¶å†…å®¹ï¼Œç»™å‡ºå¤„ç†ä¼˜å…ˆçº§å»ºè®®

**è¯­è¨€é£æ ¼è¦æ±‚**ï¼š
- ä½¿ç”¨"æ‚¨"è€Œä¸æ˜¯"ä½ "ï¼Œä½“ç°ä¸“ä¸šæ€§
- è¯­æ°”æ¸©æš–ã€ç”ŸåŠ¨ã€æ´»æ³¼ï¼Œä½†ä¸å¤±ä¸“ä¸š
- ç”¨emojiå¢åŠ äº²å’ŒåŠ›ï¼ˆé€‚åº¦ä½¿ç”¨ï¼Œä¸è¦è¿‡å¤šï¼‰
- é‡è¦ä¿¡æ¯ç”¨åŠ ç²—æˆ–ç‰¹æ®Šç¬¦å·æ ‡æ³¨
- é¿å…æœºæ¢°åŒ–ã€å‘†æ¿çš„è¡¨è¿°ï¼Œè¦è‡ªç„¶æµç•…ã€å……æ»¡æ´»åŠ›
- å¯ä»¥ä½¿ç”¨æ¯”å–»ã€æ‹Ÿäººç­‰ä¿®è¾æ‰‹æ³•ï¼Œè®©æ–‡å­—æ›´ç”ŸåŠ¨
- é€‚å½“å¢åŠ ä¸€äº›è¶£å‘³æ€§çš„è¡¨è¾¾ï¼Œä½†ä¿æŒä¸“ä¸šåº¦

è¯·ç›´æ¥è¾“å‡ºæ‘˜è¦å†…å®¹ï¼Œä¸è¦åŠ ä»»ä½•å‰ç¼€æˆ–è§£é‡Šã€‚
"""
        
        try:
            # è°ƒç”¨AIç”Ÿæˆæ™ºèƒ½æ‘˜è¦
            if self.provider == 'glm':
                summary = self._call_glm_api(prompt)
            elif self.provider == 'openai':
                summary = self._call_openai_api(prompt)
            else:
                summary = None
            
            # å¦‚æœAIç”ŸæˆæˆåŠŸï¼Œè¿”å›
            if summary:
                return summary
            
            # AIå¤±è´¥ï¼Œä½¿ç”¨å¢å¼ºç‰ˆå¤‡ç”¨æ‘˜è¦
            return self._generate_enhanced_fallback_summary(
                total_count, urgent_emails, important_emails, meetings, 
                tasks, deadlines, financial_items, categories, is_manual_fetch
            )
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæ™ºèƒ½æ‘˜è¦å¤±è´¥: {e}")
            return self._generate_enhanced_fallback_summary(
                total_count, urgent_emails, important_emails, meetings, 
                tasks, deadlines, financial_items, categories, is_manual_fetch
            )
    
    def _generate_enhanced_fallback_summary(self, total_count, urgent_emails, important_emails, 
                                          meetings, tasks, deadlines, financial_items, categories, is_manual_fetch=False):
        """ç”Ÿæˆå¢å¼ºç‰ˆå¤‡ç”¨æ‘˜è¦ï¼ˆå½“AIä¸å¯ç”¨æ—¶ï¼‰
        
        Args:
            is_manual_fetch: æ˜¯å¦ä¸ºæ‰‹åŠ¨å®æ—¶æ”¶å–
        """
        # ä½¿ç”¨ä¸œå…«åŒºæ—¶é—´
        from utils.timezone_helper import now_china_naive
        
        summary_parts = []
        
        # æ ¹æ®æ”¶å–æ–¹å¼å†³å®šå¼€åœº
        if is_manual_fetch:
            # æ‰‹åŠ¨æ”¶å–ï¼šç›´æ¥èšç„¦å†…å®¹
            summary_parts.append(f"æœ¬æ¬¡ä¸ºæ‚¨æ”¶å–äº† **{total_count}** å°é‚®ä»¶")
        else:
            # å®šæ—¶æ”¶å–ï¼šä½¿ç”¨åŸºäºä¸œå…«åŒºçš„æ—¶é—´é—®å€™
            china_time = now_china_naive()
            hour = china_time.hour
            if 6 <= hour < 12:
                greeting = "æ—©ä¸Šå¥½ï¼â˜€ï¸"
            elif 12 <= hour < 18:
                greeting = "ä¸‹åˆå¥½ï¼ğŸŒ¤ï¸"
            else:
                greeting = "æ™šä¸Šå¥½ï¼ğŸŒ™"
            
            summary_parts.append(greeting)
            summary_parts.append(f"å·²ä¸ºæ‚¨æ•´ç†äº† **{total_count}** å°é‚®ä»¶")
        
        # ç´§æ€¥æé†’ï¼ˆæ›´ç”ŸåŠ¨çš„è¡¨è¿°ï¼‰
        if urgent_emails:
            summary_parts.append(f"âš ï¸ å‘ç° **{len(urgent_emails)}** å°ç´§æ€¥é‚®ä»¶ï¼Œå»ºè®®ç«‹å³å…³æ³¨")
            if urgent_emails[0]:
                subject = urgent_emails[0].get('subject', '')
                summary_parts.append(f"ğŸ“Œ æœ€ç´§æ€¥çš„æ˜¯ï¼šã€Š{subject}ã€‹")
        
        # ä¼šè®®æé†’ï¼ˆæ›´æ´»æ³¼ï¼‰
        if meetings:
            summary_parts.append(f"ğŸ“… ä»Šå¤©æ’äº† **{len(meetings)}** åœºä¼šè®®ï¼Œè®°å¾—æå‰å‡†å¤‡")
        
        # ä»»åŠ¡æé†’ï¼ˆå¢åŠ æ´»åŠ›ï¼‰
        if tasks:
            summary_parts.append(f"âœ… æœ‰ **{len(tasks)}** é¡¹å¾…åŠä»»åŠ¡ç­‰ç€æ‚¨ï¼ŒåŠ æ²¹")
        
        # æˆªæ­¢æ—¥æœŸï¼ˆå¢åŠ ç´§è¿«æ„Ÿï¼‰
        if deadlines:
            summary_parts.append(f"â° **{len(deadlines)}** ä¸ªäº‹é¡¹ä¸´è¿‘æˆªæ­¢ï¼Œæ—¶é—´ç´§è¿«ï¼Œè¯·æ³¨æ„")
        
        # è´¢åŠ¡æé†’ï¼ˆæ›´é†’ç›®ï¼‰
        if financial_items:
            summary_parts.append(f"ğŸ’° æ”¶åˆ° **{len(financial_items)}** å°è´¢åŠ¡ç›¸å…³é‚®ä»¶ï¼Œè¯·åŠæ—¶æŸ¥çœ‹")
        
        # å…¶ä»–åˆ†ç±»
        if important_emails and not urgent_emails:
            summary_parts.append(f"å¦æœ‰ **{len(important_emails)}** å°é‡è¦é‚®ä»¶å€¼å¾—å…³æ³¨")
        
        # è´´å¿ƒå»ºè®®ï¼ˆæ›´ç”ŸåŠ¨ï¼‰
        if urgent_emails or deadlines:
            summary_parts.append("ğŸ¯ å»ºè®®æŒ‰ä¼˜å…ˆçº§å¤„ç†ï¼šç´§æ€¥é‚®ä»¶ > ä¸´è¿‘deadline > å…¶ä»–äº‹é¡¹")
        elif meetings:
            summary_parts.append("ğŸ¯ å»ºè®®å…ˆç¡®è®¤ä¼šè®®æ—¶é—´ï¼Œåšå¥½å……åˆ†å‡†å¤‡")
        else:
            summary_parts.append("ğŸ˜Š é‚®ä»¶éƒ½æ¯”è¾ƒå¸¸è§„ï¼Œå¯ä»¥ä»å®¹åº”å¯¹")
        
        return "ã€‚".join(summary_parts) + "ã€‚"
    
    def generate(self, prompt: str, temperature: float = 0.7, max_tokens: int = 2000) -> Optional[str]:
        """
        é€šç”¨çš„AIæ–‡æœ¬ç”Ÿæˆæ–¹æ³•
        
        å‚æ•°:
        - prompt: æç¤ºè¯
        - temperature: æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§ï¼ˆ0-1ï¼‰
        - max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
        
        è¿”å›:
        - ç”Ÿæˆçš„æ–‡æœ¬ï¼Œå¤±è´¥è¿”å›None
        """
        if self.provider == 'glm':
            return self._generate_with_glm(prompt, temperature, max_tokens)
        elif self.provider == 'openai':
            return self._generate_with_openai(prompt, temperature, max_tokens)
        else:
            logger.error(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {self.provider}")
            return None
    
    def _generate_with_glm(self, prompt: str, temperature: float, max_tokens: int) -> Optional[str]:
        """ä½¿ç”¨GLMç”Ÿæˆæ–‡æœ¬"""
        if not self.api_key:
            logger.error("GLM API key æœªé…ç½®")
            return None
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": False
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    content = result['choices'][0]['message']['content'].strip()
                    return content
                else:
                    logger.error("GLM API è¿”å›æ ¼å¼é”™è¯¯")
                    return None
            else:
                error_text = response.text
                logger.error(f"GLM API è°ƒç”¨å¤±è´¥: {response.status_code} - {error_text}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("GLM API è°ƒç”¨è¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"GLM API è°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    def _generate_with_openai(self, prompt: str, temperature: float, max_tokens: int) -> Optional[str]:
        """ä½¿ç”¨OpenAIç”Ÿæˆæ–‡æœ¬"""
        if not self.api_key:
            logger.error("OpenAI API key æœªé…ç½®")
            return None
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and len(result['choices']) > 0:
                    content = result['choices'][0]['message']['content'].strip()
                    return content
                else:
                    logger.error("OpenAI API è¿”å›æ ¼å¼é”™è¯¯")
                    return None
            else:
                error_text = response.text
                logger.error(f"OpenAI API è°ƒç”¨å¤±è´¥: {response.status_code} - {error_text}")
                return None
                
        except requests.exceptions.Timeout:
            logger.error("OpenAI API è°ƒç”¨è¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"OpenAI API è°ƒç”¨å¼‚å¸¸: {e}")
            return None
    
    # ========================================================================
    # Function Call æ”¯æŒ
    # ========================================================================
    
    def chat_with_tools(self, messages: List[Dict], tools: List[Dict] = None, 
                       temperature: float = 0.7, max_tokens: int = 2000) -> Dict:
        """
        ä½¿ç”¨Function Callèƒ½åŠ›è¿›è¡Œå¯¹è¯
        
        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{"role": "user", "content": "..."}]
            tools: å·¥å…·å®šä¹‰åˆ—è¡¨ï¼ˆFunction Callæ ¼å¼ï¼‰
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§tokenæ•°
        
        Returns:
            {
                'content': 'å›å¤å†…å®¹',
                'tool_calls': [å·¥å…·è°ƒç”¨åˆ—è¡¨],
                'finish_reason': 'ç»“æŸåŸå› ',
                'usage': {ä½¿ç”¨ç»Ÿè®¡}
            }
        """
        if self.provider == 'glm':
            return self._chat_with_tools_glm(messages, tools, temperature, max_tokens)
        elif self.provider == 'openai':
            return self._chat_with_tools_openai(messages, tools, temperature, max_tokens)
        else:
            logger.error(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {self.provider}")
            return {
                'content': '',
                'tool_calls': [],
                'finish_reason': 'error',
                'error': f'ä¸æ”¯æŒçš„AIæä¾›å•†: {self.provider}'
            }
    
    def _chat_with_tools_glm(self, messages: List[Dict], tools: List[Dict], 
                            temperature: float, max_tokens: int) -> Dict:
        """ä½¿ç”¨GLM-4 Function Call"""
        if not self.api_key:
            logger.error("GLM API key æœªé…ç½®")
            return {
                'content': '',
                'tool_calls': [],
                'finish_reason': 'error',
                'error': 'GLM API key æœªé…ç½®'
            }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": False
        }
        
        # æ·»åŠ å·¥å…·å®šä¹‰
        if tools:
            payload["tools"] = tools
            payload["tool_choice"] = "auto"  # è®©æ¨¡å‹è‡ªåŠ¨å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·
        
        logger.info(f"GLM Function Call è¯·æ±‚: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=60  # Function Callå¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info(f"GLM Function Call å“åº”: {json.dumps(result, ensure_ascii=False, indent=2)}")
                
                if 'choices' in result and len(result['choices']) > 0:
                    choice = result['choices'][0]
                    message = choice['message']
                    
                    return {
                        'content': message.get('content', ''),
                        'tool_calls': message.get('tool_calls', []),
                        'finish_reason': choice.get('finish_reason', 'stop'),
                        'usage': result.get('usage', {})
                    }
                else:
                    logger.error("GLM API è¿”å›æ ¼å¼é”™è¯¯")
                    return {
                        'content': '',
                        'tool_calls': [],
                        'finish_reason': 'error',
                        'error': 'GLM API è¿”å›æ ¼å¼é”™è¯¯'
                    }
            else:
                error_text = response.text
                logger.error(f"GLM Function Call å¤±è´¥: {response.status_code} - {error_text}")
                return {
                    'content': '',
                    'tool_calls': [],
                    'finish_reason': 'error',
                    'error': f'GLM API è°ƒç”¨å¤±è´¥: {response.status_code}'
                }
                
        except requests.exceptions.Timeout:
            logger.error("GLM Function Call è¶…æ—¶")
            return {
                'content': '',
                'tool_calls': [],
                'finish_reason': 'error',
                'error': 'GLM API è°ƒç”¨è¶…æ—¶'
            }
        except Exception as e:
            logger.error(f"GLM Function Call å¼‚å¸¸: {e}", exc_info=True)
            return {
                'content': '',
                'tool_calls': [],
                'finish_reason': 'error',
                'error': f'GLM API è°ƒç”¨å¼‚å¸¸: {str(e)}'
            }
    
    def _chat_with_tools_openai(self, messages: List[Dict], tools: List[Dict], 
                               temperature: float, max_tokens: int) -> Dict:
        """ä½¿ç”¨OpenAI Function Call"""
        if not self.api_key:
            logger.error("OpenAI API key æœªé…ç½®")
            return {
                'content': '',
                'tool_calls': [],
                'finish_reason': 'error',
                'error': 'OpenAI API key æœªé…ç½®'
            }
        
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        
        # æ·»åŠ å·¥å…·å®šä¹‰
        if tools:
            payload["tools"] = tools
            payload["tool_choice"] = "auto"
        
        logger.info(f"OpenAI Function Call è¯·æ±‚: {json.dumps(payload, ensure_ascii=False, indent=2)}")
        
        try:
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=headers,
                json=payload,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                logger.info(f"OpenAI Function Call å“åº”: {json.dumps(result, ensure_ascii=False, indent=2)}")
                
                if 'choices' in result and len(result['choices']) > 0:
                    choice = result['choices'][0]
                    message = choice['message']
                    
                    return {
                        'content': message.get('content', ''),
                        'tool_calls': message.get('tool_calls', []),
                        'finish_reason': choice.get('finish_reason', 'stop'),
                        'usage': result.get('usage', {})
                    }
                else:
                    logger.error("OpenAI API è¿”å›æ ¼å¼é”™è¯¯")
                    return {
                        'content': '',
                        'tool_calls': [],
                        'finish_reason': 'error',
                        'error': 'OpenAI API è¿”å›æ ¼å¼é”™è¯¯'
                    }
            else:
                error_text = response.text
                logger.error(f"OpenAI Function Call å¤±è´¥: {response.status_code} - {error_text}")
                return {
                    'content': '',
                    'tool_calls': [],
                    'finish_reason': 'error',
                    'error': f'OpenAI API è°ƒç”¨å¤±è´¥: {response.status_code}'
                }
                
        except requests.exceptions.Timeout:
            logger.error("OpenAI Function Call è¶…æ—¶")
            return {
                'content': '',
                'tool_calls': [],
                'finish_reason': 'error',
                'error': 'OpenAI API è°ƒç”¨è¶…æ—¶'
            }
        except Exception as e:
            logger.error(f"OpenAI Function Call å¼‚å¸¸: {e}", exc_info=True)
            return {
                'content': '',
                'tool_calls': [],
                'finish_reason': 'error',
                'error': f'OpenAI API è°ƒç”¨å¼‚å¸¸: {str(e)}'
            }